{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import re\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load our dataframe with features calculated in the feature selection notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 1min, total: 2min 31s\n",
      "Wall time: 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import cPickle\n",
    "import praw\n",
    "\n",
    "df = cPickle.load(open('df_features.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_replies</th>\n",
       "      <th>_submission</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>body_html</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>created</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>downs</th>\n",
       "      <th>gilded</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>thread</th>\n",
       "      <th>ups</th>\n",
       "      <th>character_count</th>\n",
       "      <th>time_delay</th>\n",
       "      <th>word_count</th>\n",
       "      <th>swear_count</th>\n",
       "      <th>word_size</th>\n",
       "      <th>link_count</th>\n",
       "      <th>italics_count</th>\n",
       "      <th>bold_count</th>\n",
       "      <th>strikethrough_count</th>\n",
       "      <th>blockquote_count</th>\n",
       "      <th>paragraph_count</th>\n",
       "      <th>i_author_flair_css_class</th>\n",
       "      <th>i_author_flair_text</th>\n",
       "      <th>i_distinguished</th>\n",
       "      <th>i_edited</th>\n",
       "      <th>i_score_hidden</th>\n",
       "      <th>i_banned_by</th>\n",
       "      <th>syn_count</th>\n",
       "      <th>syn_perc</th>\n",
       "      <th>un_length</th>\n",
       "      <th>un_punc</th>\n",
       "      <th>un_case</th>\n",
       "      <th>un_number</th>\n",
       "      <th>un_PM</th>\n",
       "      <th>un_bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[This one is rudimentary., chugada chugada chu...</td>\n",
       "      <td>4701 :: What is one sentence that people in yo...</td>\n",
       "      <td>SweetJesusRyan</td>\n",
       "      <td>It's just flam taps followed by a paradiddle a...</td>\n",
       "      <td>&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s just flam taps fol...</td>\n",
       "      <td>0</td>\n",
       "      <td>1432091072</td>\n",
       "      <td>1432062272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2485</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>36ih74</td>\n",
       "      <td>2485</td>\n",
       "      <td>60</td>\n",
       "      <td>7011</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Yes, we dont want any zombies hanging around....</td>\n",
       "      <td>4701 :: What is one sentence that people in yo...</td>\n",
       "      <td>Slak44</td>\n",
       "      <td>If the parent isn't responding, just kill him ...</td>\n",
       "      <td>&lt;div class=\"md\"&gt;&lt;p&gt;If the parent isn&amp;#39;t res...</td>\n",
       "      <td>0</td>\n",
       "      <td>1432087085</td>\n",
       "      <td>1432058285</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4983</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>36ih74</td>\n",
       "      <td>4983</td>\n",
       "      <td>63</td>\n",
       "      <td>3024</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Is your hobby being John Gruden?, This guy he...</td>\n",
       "      <td>4701 :: What is one sentence that people in yo...</td>\n",
       "      <td>rylnalyevo</td>\n",
       "      <td>FB is always the primary on Spider 2 Y Banana.</td>\n",
       "      <td>&lt;div class=\"md\"&gt;&lt;p&gt;FB is always the primary on...</td>\n",
       "      <td>0</td>\n",
       "      <td>1432090391</td>\n",
       "      <td>1432061591</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2386</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>36ih74</td>\n",
       "      <td>2386</td>\n",
       "      <td>46</td>\n",
       "      <td>6330</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            _replies                                        _submission          author                                               body                                          body_html  controversiality     created  created_utc  downs  gilded  score  subreddit  thread   ups  character_count  time_delay  word_count  swear_count  word_size  link_count  italics_count  bold_count  strikethrough_count  blockquote_count  paragraph_count  i_author_flair_css_class  \\\n",
       "0  [This one is rudimentary., chugada chugada chu...  4701 :: What is one sentence that people in yo...  SweetJesusRyan  It's just flam taps followed by a paradiddle a...  <div class=\"md\"><p>It&#39;s just flam taps fol...                 0  1432091072   1432062272      0       0   2485  AskReddit  36ih74  2485               60        7011          12            0          4           0              0           0                    0                 0                1                         0   \n",
       "1  [Yes, we dont want any zombies hanging around....  4701 :: What is one sentence that people in yo...          Slak44  If the parent isn't responding, just kill him ...  <div class=\"md\"><p>If the parent isn&#39;t res...                 0  1432087085   1432058285      0       1   4983  AskReddit  36ih74  4983               63        3024          12            0          4           0              0           0                    0                 0                1                         0   \n",
       "2  [Is your hobby being John Gruden?, This guy he...  4701 :: What is one sentence that people in yo...      rylnalyevo     FB is always the primary on Spider 2 Y Banana.  <div class=\"md\"><p>FB is always the primary on...                 0  1432090391   1432061591      0       0   2386  AskReddit  36ih74  2386               46        6330          10            0          3           0              0           0                    0                 0                1                         0   \n",
       "\n",
       "   i_author_flair_text  i_distinguished i_edited  i_score_hidden  i_banned_by  syn_count  syn_perc  un_length  un_punc  un_case  un_number  un_PM  un_bot  \n",
       "0                    0                0        0               0            0          0         0         14        0        2   0.000000      0       0  \n",
       "1                    0                0        0               0            0          0         0          6        0        2   0.333333      0       0  \n",
       "2                    0                0        0               0            0          0         0         10        0        0   0.000000      0       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftouse = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by standardizing the parts of the data that are integers or floats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STANDARDIZABLE = ['created', 'created_utc', 'character_count', 'time_delay', 'word_count', 'swear_count',\n",
    "                 'word_size', 'link_count', 'italics_count', 'bold_count', 'strikethrough_count', 'blockquote_count',\n",
    "                 'paragraph_count', 'syn_count', 'syn_perc', 'un_length', 'un_punc', 'un_case', 'un_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standardize(orig_df, change_df):\n",
    "    for col in STANDARDIZABLE:\n",
    "        valstrain = orig_df[col].values[mask]\n",
    "        valstest = orig_df[col].values[~mask]\n",
    "        scaler = StandardScaler().fit(valstrain)\n",
    "        outtrain = scaler.transform(valstrain)\n",
    "        outtest = scaler.fit_transform(valstest)\n",
    "        out = np.empty(mask.shape[0])\n",
    "        out[mask] = outtrain\n",
    "        out[~mask] = outtest\n",
    "        change_df[col] = out\n",
    "\n",
    "standardize(df, dftouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "itrain, itest = train_test_split(xrange(dftouse.shape[0]), train_size=0.7)\n",
    "\n",
    "mask=np.ones(dftouse.shape[0], dtype='int')\n",
    "mask[itrain]=1\n",
    "mask[itest]=0\n",
    "mask = (mask==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a baseline where we simply guess the number of upvotes a post will get by guessing using the mean and the median of the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline(indf, mask):\n",
    "    X = indf['ups']\n",
    "    if mask !=None:\n",
    "        Xtrain, Xtest = X[mask], X[~mask]\n",
    "\n",
    "    mean = np.mean(Xtrain)\n",
    "    median = np.median(Xtrain)\n",
    "    print mean, median\n",
    "    training_error_mean = abs(Xtrain - mean)\n",
    "    training_error_median = abs(Xtrain - median)\n",
    "    \n",
    "    test_error_mean = abs(Xtest - mean)\n",
    "    test_error_median = abs(Xtest - median)\n",
    "    \n",
    "    training_accuracy1 = np.mean(training_error_mean)\n",
    "    training_accuracy2 = np.mean(training_error_median)\n",
    "    test_accuracy1 = np.mean(test_error_mean)\n",
    "    test_accuracy2 = np.mean(test_error_median)\n",
    "    \n",
    "    print \"############# Baseline Accuracy ########################\"\n",
    "    print \"Accuracy on training data using mean:   %0.2f\" % (training_accuracy1)\n",
    "    print \"Accuracy on training data using median: %0.2f\" % (training_accuracy2)\n",
    "    print \"Accuracy on test data using mean:       %0.2f\" % (test_accuracy1)\n",
    "    print \"Accuracy on test data using median:     %0.2f\" % (test_accuracy2)\n",
    "    print \"########################################################\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.3385934016 2.0\n",
      "############# Baseline Accuracy ########################\n",
      "Accuracy on training data using mean:   144.13\n",
      "Accuracy on training data using median: 77.75\n",
      "Accuracy on test data using mean:       148.93\n",
      "Accuracy on test data using median:     82.87\n",
      "########################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:3: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "baseline(dftouse, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Adjustments, Processing, and Some Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create a smaller dataframe ```minidf``` to test models that take longer to run -- below, we randomly sample 10,000 rows in the original dataframe, and create a mask for ```minidf```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "rows = random.sample(dftouse.index, 10000)\n",
    "minidf = dftouse.ix[rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "itrain2, itest2 = train_test_split(xrange(minidf.shape[0]), train_size=0.7)\n",
    "\n",
    "mask2=np.ones(minidf.shape[0], dtype='int')\n",
    "mask2[itrain2]=1\n",
    "mask2[itest2]=0\n",
    "mask2 = (mask2==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing to note is that our data is very skewed: the vast majority of the comments have scores < 5, while the highest scoring comments have scores > 7000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# comments with scores < 5 135285\n",
      "# comments with scores > 7000 16\n"
     ]
    }
   ],
   "source": [
    "print \"# comments with scores < 5\", len(dftouse[dftouse['ups'] < 5])\n",
    "print \"# comments with scores > 7000\", len(dftouse[dftouse['ups'] > 7000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This heavily skewed data can cause our models to do poorly. We thus try to adjust by taking the log of the number of upvotes, stored in ```log_df```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_df = dftouse.copy()\n",
    "log_df['ups'] = dftouse['ups'].map(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the columns that we want to use as features in the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['created_utc',\n",
    "        'time_delay',\n",
    "        'word_count',\n",
    "        'character_count',\n",
    "        'word_count',\n",
    "        'swear_count',\n",
    "        'word_size',\n",
    "        'link_count',\n",
    "        'italics_count',\n",
    "        'bold_count',\n",
    "        'strikethrough_count',\n",
    "        'blockquote_count',\n",
    "        'paragraph_count',\n",
    "        'syn_count',\n",
    "        'syn_perc',\n",
    "        'un_length',\n",
    "        'un_punc',\n",
    "        'un_case',\n",
    "        'un_number',\n",
    "        'un_PM',\n",
    "        'un_bot'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the function for optimizing parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "def cv_optimize(clf, parameters, X, y, n_folds=5, score_func=None):\n",
    "    if score_func:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, scoring=score_func)\n",
    "    else:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds)\n",
    "    gs.fit(X, y)\n",
    "    print \"BEST\", gs.best_params_, gs.best_score_, gs.grid_scores_\n",
    "    best = gs.best_estimator_\n",
    "    return best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the function to handle the regressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def classify(clf, parameters, indf, featurenames, targetname, mask=None, reuse_split=None, score_func=None, n_folds=5):\n",
    "    subdf=indf[featurenames]\n",
    "    X=subdf.values\n",
    "    y=indf[targetname].values\n",
    "    if mask !=None:\n",
    "        print \"mask\"\n",
    "        Xtrain, Xtest, ytrain, ytest = X[mask], X[~mask], y[mask], y[~mask]\n",
    "    if reuse_split !=None:\n",
    "        print \"reuse split\"\n",
    "        Xtrain, Xtest, ytrain, ytest = reuse_split['Xtrain'], reuse_split['Xtest'], reuse_split['ytrain'], reuse_split['ytest']\n",
    "    if parameters:\n",
    "        clf = cv_optimize(clf, parameters, Xtrain, ytrain, n_folds=n_folds, score_func=score_func)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    print \"############# based on standard predict ################\"\n",
    "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "    print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
    "    # print confusion_matrix(ytest, clf.predict(Xtest))\n",
    "    print \"########################################################\"\n",
    "    return clf, Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Botany and Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Decision Trees\n",
    "\n",
    "We first try regression using Decision Trees; note that we use ```log_df```. The main issue for decision trees is overfitting -- from [the documentation](http://scikit-learn.org/stable/modules/tree.html#tips-on-practical-use), to get a feel for how the tree is fitting the data, we use ```max_depth=3``` and ```min_samples_leaf=5```, then visualize the tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask\n",
      "BEST {'max_depth': 3, 'min_samples_leaf': 5} -0.733127291569 [mean: -0.73313, std: 0.02627, params: {'max_depth': 3, 'min_samples_leaf': 5}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.28\n",
      "Accuracy on test data:     0.28\n",
      "########################################################\n",
      "[('created_utc', 0.0), ('time_delay', 0.92271611118651675), ('word_count', 0.0), ('character_count', 0.039319987686596794), ('word_count', 0.013935803602994141), ('swear_count', 0.0), ('word_size', 0.0), ('link_count', 0.0), ('italics_count', 0.0), ('bold_count', 0.0), ('strikethrough_count', 0.0), ('blockquote_count', 0.0), ('paragraph_count', 0.024028097523892362), ('syn_count', 0.0), ('syn_perc', 0.0), ('un_length', 0.0), ('un_punc', 0.0), ('un_case', 0.0), ('un_number', 0.0), ('un_PM', 0.0), ('un_bot', 0.0)]\n",
      "CPU times: user 2.34 s, sys: 84.4 ms, total: 2.42 s\n",
      "Wall time: 2.49 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:7: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parameters = {\"max_depth\": [3], 'min_samples_leaf': [5]}\n",
    "clftree, Xtrain, ytrain, Xtest, ytest = classify(\n",
    "                              DecisionTreeRegressor(),\n",
    "                              parameters, \n",
    "                              log_df, \n",
    "                              cols,\n",
    "                              'ups',\n",
    "                              mask = mask,\n",
    "                              score_func = 'mean_absolute_error',\n",
    "                              n_folds = 5\n",
    "                              )\n",
    "\n",
    "tree.export_graphviz(clftree, out_file='tree.dot') # get the tree as a dot file, then convert to png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the tree that results from ```max_depth=3``` and ```min_samples_leaf=5```: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of decision tree](images/decisiontree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging by the MSE (mean squared error) of the children, we are not overfitting. We thus increase ```max_depth``` and ```min_samples_leaf```. We also save the feature importances in ```tree_feats```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask\n",
      "BEST {'max_depth': 4, 'min_samples_leaf': 1} -0.724749544048 [mean: -0.73313, std: 0.02627, params: {'max_depth': 3, 'min_samples_leaf': 1}, mean: -0.73313, std: 0.02627, params: {'max_depth': 3, 'min_samples_leaf': 2}, mean: -0.73313, std: 0.02627, params: {'max_depth': 3, 'min_samples_leaf': 3}, mean: -0.73313, std: 0.02627, params: {'max_depth': 3, 'min_samples_leaf': 4}, mean: -0.73313, std: 0.02627, params: {'max_depth': 3, 'min_samples_leaf': 5}, mean: -0.73313, std: 0.02627, params: {'max_depth': 3, 'min_samples_leaf': 6}, mean: -0.72475, std: 0.01835, params: {'max_depth': 4, 'min_samples_leaf': 1}, mean: -0.72475, std: 0.01835, params: {'max_depth': 4, 'min_samples_leaf': 2}, mean: -0.72475, std: 0.01835, params: {'max_depth': 4, 'min_samples_leaf': 3}, mean: -0.72475, std: 0.01835, params: {'max_depth': 4, 'min_samples_leaf': 4}, mean: -0.72475, std: 0.01835, params: {'max_depth': 4, 'min_samples_leaf': 5}, mean: -0.72475, std: 0.01835, params: {'max_depth': 4, 'min_samples_leaf': 6}, mean: -0.73305, std: 0.01851, params: {'max_depth': 5, 'min_samples_leaf': 1}, mean: -0.73305, std: 0.01851, params: {'max_depth': 5, 'min_samples_leaf': 2}, mean: -0.73305, std: 0.01851, params: {'max_depth': 5, 'min_samples_leaf': 3}, mean: -0.73305, std: 0.01851, params: {'max_depth': 5, 'min_samples_leaf': 4}, mean: -0.73305, std: 0.01851, params: {'max_depth': 5, 'min_samples_leaf': 5}, mean: -0.73305, std: 0.01851, params: {'max_depth': 5, 'min_samples_leaf': 6}, mean: -0.73351, std: 0.01914, params: {'max_depth': 6, 'min_samples_leaf': 1}, mean: -0.73360, std: 0.01912, params: {'max_depth': 6, 'min_samples_leaf': 2}, mean: -0.73356, std: 0.01913, params: {'max_depth': 6, 'min_samples_leaf': 3}, mean: -0.73353, std: 0.01912, params: {'max_depth': 6, 'min_samples_leaf': 4}, mean: -0.73327, std: 0.01931, params: {'max_depth': 6, 'min_samples_leaf': 5}, mean: -0.73326, std: 0.01918, params: {'max_depth': 6, 'min_samples_leaf': 6}, mean: -0.75134, std: 0.01641, params: {'max_depth': 7, 'min_samples_leaf': 1}, mean: -0.75134, std: 0.01660, params: {'max_depth': 7, 'min_samples_leaf': 2}, mean: -0.75153, std: 0.01674, params: {'max_depth': 7, 'min_samples_leaf': 3}, mean: -0.75142, std: 0.01672, params: {'max_depth': 7, 'min_samples_leaf': 4}, mean: -0.75143, std: 0.01680, params: {'max_depth': 7, 'min_samples_leaf': 5}, mean: -0.75125, std: 0.01658, params: {'max_depth': 7, 'min_samples_leaf': 6}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.30\n",
      "Accuracy on test data:     0.30\n",
      "########################################################\n",
      "CPU times: user 1min 13s, sys: 1.71 s, total: 1min 15s\n",
      "Wall time: 1min 17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:7: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parameters = {\"max_depth\": [3, 4, 5, 6, 7], 'min_samples_leaf': [1, 2, 3, 4, 5, 6]}\n",
    "clftree, Xtrain, ytrain, Xtest, ytest = classify(\n",
    "                              DecisionTreeRegressor(),\n",
    "                              parameters, \n",
    "                              log_df, \n",
    "                              cols,\n",
    "                              'ups',\n",
    "                              mask = mask,\n",
    "                              score_func = 'mean_absolute_error',\n",
    "                              n_folds = 5\n",
    "                              )\n",
    "\n",
    "tree_feats = zip(cols, clftree.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too hot for accuracy scores. Let's look at the mean absolute error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.250330521\n"
     ]
    }
   ],
   "source": [
    "print np.mean(abs(np.exp(clftree.predict(Xtest)) - np.exp(ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is barely better than the baseline of the median!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try Random Forests. According to [the documentation](http://scikit-learn.org/stable/modules/ensemble.html#parameters), the main parameters to adjuct are ```n_estimators``` and ```max_features```. \n",
    "\n",
    "* ```n_estimators``` is the number of trees in the forest -- the more trees, the better but longer to compute. \n",
    "\n",
    "* ```max_features``` is the number of random subsets of features to consider when splitting a node. The documentation states that empirically, the default value of n_features (the number of features) is the best for regression.\n",
    "\n",
    "* Good results can be achieved when using ```min_samples_split = 1```. ```min_samples_split``` is the minimum number of samples needed to split an internal node -- the default is 2, but if we set it equal to 1, the trees are fully developed (which has the downfall of using lots of RAM). \n",
    "\n",
    "* Finally, since we are building lots of trees, we want to run this in parallel: we thus set ```n_jobs=-1```, which means that the number of jobs is set to the number of cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the regression below, and save the feature importances in ```forest_feats```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "parameters = {'n_estimators': range(10, 30), \n",
    "              'min_samples_split': [1, 2], 'n_jobs': [-1]}\n",
    "clfforest, Xtrain, ytrain, Xtest, ytest = classify(\n",
    "                              RandomForestRegressor(),\n",
    "                              parameters, \n",
    "                              log_df, \n",
    "                              cols,\n",
    "                              'ups',\n",
    "                              mask = mask,\n",
    "                              score_func = 'mean_absolute_error',\n",
    "                              n_folds = 5\n",
    "                              )\n",
    "\n",
    "forest_feats = zip(cols, clfforest.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126.834577495\n"
     ]
    }
   ],
   "source": [
    "print np.mean(abs(np.exp(clfforest.predict(Xtest)) - np.exp(ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Feature Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how each model weighted the features we provided it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Logistic Regression with Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask\n",
      "BEST {'C': 0.1} -87.7792857143 [mean: -87.77929, std: 134.49530, params: {'C': 0.1}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.43\n",
      "Accuracy on test data:     0.43\n",
      "########################################################\n",
      "CPU times: user 22 s, sys: 1.28 s, total: 23.2 s\n",
      "Wall time: 23.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:7: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clflog, Xtrain, ytrain, Xtest, ytest = classify(\n",
    "                              LogisticRegression(penalty=\"l1\"),\n",
    "                              {\"C\": [0.1]}, \n",
    "                              minidf, \n",
    "                              cols,\n",
    "                              'ups',\n",
    "                              mask = mask2,\n",
    "                              score_func = 'mean_absolute_error',\n",
    "                              n_folds = 5\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.4613333333\n"
     ]
    }
   ],
   "source": [
    "print np.mean(abs(clflog.predict(Xtest) - ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
